{
  "copyright_text": null,
  "description": "Word embeddings (like GloVe, fastText and word2vec) are very powerful for capturing general word semantics. What if your use case is domain specific? Will your embeddings still work? If they don\u2019t, how do you retrain them?",
  "duration": 1806,
  "language": "eng",
  "recorded": "2018-05-26",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://pydata.org/amsterdam2018/schedule/"
    }
  ],
  "speakers": [
    "Jetze Schuurmans"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/DPIt7yXr-Lw/maxresdefault.jpg",
  "title": "(Re)training word embeddings for a specific domain",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=DPIt7yXr-Lw"
    }
  ]
}
