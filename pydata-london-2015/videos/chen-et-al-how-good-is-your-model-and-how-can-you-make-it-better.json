{
  "description": "The objective of this tutorial is to give participants the skills\nrequired to validate, evaluate and fine-tune models using scikit-learn\u2019s\nevaluation metrics and parameter search capabilities. It will combine\nboth the theoretical rationale behind these methods and their code\nimplementation.\n\nThe session will be structured as follows (rough timings in\nparentheses):\n\n1. Explanation of over-fitting and the bias-variance trade-off, followed\n   by a brief conceptual overview of cross-validation, bootstrapping,\n   and ensemble methods, in particular with respect to bias and\n   variance. Pointers to the corresponding scikit-learn functions will\n   also be given. (20 minutes)\n2. Implementation of cross-validation and grid-search method for\n   parameter tuning, using KNN classification as an illustrative\n   example. Participants will train two KNN neighbours with different\n   numbers of neighbours on preprocessed data (provided). They will then\n   be guided through cross-validation, plotting of results, and\n   grid-search to find the best neighbour and weight configuration(s).\n   (30 minutes)\n3. Comparison of different classification models using cross-validation.\n   Participants will implement a logistic regression, linear and\n   non-linear support vector machine (SVM) or neural network model and\n   apply the same cross-validation and grid search method as in the\n   guided KNN example. Participants will then compare their plots,\n   evaluate their results and discuss which model they might choose for\n   different objectives, trading off generalisability, accuracy, speed\n   and randomness. (70 minutes)\n\nWe assume participants will be familiar with numpy, matplotlib, and at\nleast the intuition behind some of the main classification algorithms.\nBefore the tutorial, participants with github accounts should fork from\nhttps://github.com/cambridgecoding/pydata-tutorial or download the files\nand iPython notebook so they can participate in the hands on activities.\nRequired libraries: numpy, scikit-learn, matplotlib, pandas, scipy,\nmultilayer\\_perceptron (provided)\n",
  "duration": 3754,
  "recorded": "2015-06-19",
  "speakers": [
    "Chih-Chun Chen",
    "Elena Chatzimichali"
  ],
  "summary": "This hands-on tutorial will show you how to use scikit-learn\u2019s model\nevaluation functions to evaluate different models in terms of\naccuracy and generalisability, and search for optimal parameter\nconfigurations.\n",
  "tags": [
    "tutorial"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/oKHeAtOgMNA/hqdefault.jpg",
  "title": "How \u201cgood\u201d is your model, and how can you make it better?",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=oKHeAtOgMNA"
    }
  ]
}
