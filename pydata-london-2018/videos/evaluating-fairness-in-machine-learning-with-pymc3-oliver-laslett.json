{
  "abstract": "In this talk we will present various approaches for evaluating the\nfairness of machine learning algorithms. We measure the effect of\nprotected variables, which should not influence decision making, on the\noutput. As an example, we demonstrate a Bayesian model of fairness\nconstructed using PyMC3 and apply the model to open datasets.\n",
  "copyright_text": null,
  "description": "Machine learning and data science applications can be unintentionally\nbiased if care is not taken to evaluate their effect on different\nsub-populations. However, by using a \"fair\" approach, machine decision\nmaking can potentially be less biased than human decision makers.\n",
  "duration": 2392,
  "language": "eng",
  "recorded": "2018-04-28",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://pydata.org/london2018/schedule/"
    }
  ],
  "speakers": [
    "Oliver Laslett"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/tX5YDf42DnY/maxresdefault.jpg",
  "title": "Evaluating fairness in machine learning with PyMC3",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=tX5YDf42DnY"
    }
  ]
}
