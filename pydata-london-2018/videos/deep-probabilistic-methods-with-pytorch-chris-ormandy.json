{
  "abstract": "Deep Generative Models have become very popular recently, with VAEs and\nthen GANs gaining mainstream attention. This tutorial introduces\nVariational Inference and key extensions that form part of the theory of\nVAEs and GANs. The aim is to introduce the theory in an accessible way,\nand provide concrete examples in pytorch. This tutorial assumes a\nreasonable understanding of probability, such as key Bayesian\nterminology (prior, posterior etc) and basic information theory such as\nKL-divergence and entropy. The aim of this tutorial is not to generate\npretty pictures - but to develop understanding of these methods and\nsee/implement some key results from the machine learning literature.\n",
  "copyright_text": null,
  "description": "This tutorial aims to introduce key theory and methods in Variational\nInference and apply these in practice, ending up connecting VI and\nrecent generative model advances such as VAEs and GANs.\n",
  "duration": 4932,
  "language": "eng",
  "recorded": "2018-04-27",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://pydata.org/london2018/schedule/"
    }
  ],
  "speakers": [
    "Chris Ormandy"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/HNKlytVD1Zg/maxresdefault.jpg",
  "title": "Deep Probabilistic Methods with PyTorch",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=HNKlytVD1Zg"
    }
  ]
}
