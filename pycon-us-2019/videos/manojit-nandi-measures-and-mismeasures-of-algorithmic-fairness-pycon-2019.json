{
  "copyright_text": null,
  "description": "Within the last few years, researchers have come to understand that\nmachine learning systems may display discriminatory behavior with\nregards to certain protected characteristics, such as gender or race. To\ncombat these harmful behaviors, we have created multiple definitions of\nfairness to enable equity in machine learning algorithms. In this talk,\nI will cover these different definitions of algorithmic fairness and\ndiscuss both the strengths and limitations of these formalizations. In\naddition, I will cover other best practices to better mitigate the\nunintended bias of data products.\n",
  "duration": 2258,
  "language": "eng",
  "recorded": "2019-05-04T13:40:00",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://us.pycon.org/2019/schedule/talks/"
    },
    {
      "label": "Conference slides (github)",
      "url": "https://github.com/PyCon/2019-slides"
    },
    {
      "label": "Conference slides (speakerdeck)",
      "url": "https://speakerdeck.com/pycon2019"
    },
    {
      "label": "Talk schedule",
      "url": "https://us.pycon.org/2019/schedule/presentation/226/"
    }
  ],
  "speakers": [
    "Manojit Nandi"
  ],
  "tags": [
    "talk"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/olCKhigTVuY/maxresdefault.jpg",
  "title": "Measures and Mismeasures of algorithmic fairness",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=olCKhigTVuY"
    }
  ]
}
