{
  "description": "How do you build a big data pipeline when the size of your data starts\nto get out of hand? How do you improve on the initial model when\npeople are demanding more data, and faster?\n\nThis talk covers the evolution of a data pipeline in Python, from\ndaily full load to up-to-the-minute event stream, based on our\nexperience at FanDuel. Technologies covered include Amazon EMR,\nRedshift, Hadoop, Luigi, Spark and Kinesis. We also look at the\nchallenges and trade-offs, and building a big data engineering team.\n",
  "duration": 1645,
  "language": "eng",
  "recorded": "2016-11-05",
  "speakers": [
    "Ali King"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/zEXbOA1NEeM/hqdefault.jpg",
  "title": "Data Pipeline Evolution",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=zEXbOA1NEeM"
    }
  ]
}
