{
  "alias": "video/450/pycon-2011--supercomputer-and-cluster-application",
  "category": "PyCon US 2011",
  "copyright_text": "Creative Commons Attribution-NonCommercial-ShareAlike 3.0",
  "description": "PyCon 2011: Supercomputer and Cluster Application Performance Analysis\nusing Python\n\nPresented by Daniel W. Barnette, PhD\n\nSandia National Labs analyzes high-performance computing environments to\noptimize application performance, analyze system architectures, and\nprovide design guidance for future systems. We discuss 1) generating\nperformance data across multiple systems using mini-applications, and 2)\nusing our open source Python tools Pylot/Co-Pylot to store and analyze\ndata using a MySQL database server.\n\nAbstract\n\nSandia National Laboratories analyzes large-scale, state-of-the-art high\nperformance computing environments for the Department of Energy (DOE),\nDepartment of Defense (DoD), and other government agencies. Execution\nefficiency is vital when dealing with datasets that require billions of\nelements or when running simulations that take millions of core-hours to\ncomplete.\n\nOne approach to investigating execution efficiency is to instrument our\nlarge- scale applications and platforms to generate timings and other\nperformance data. Although effective in mature computing environments,\nworking directly with large-scale applications is cumbersome, time\nconsuming, and even impossible in the early stages of computer system\nanalysis and design. Furthermore, the software and data sets of these\napplications may be restricted, limiting our abilities to collaborate.\n\nIn order to enhance our analysis capabilities far upstream from when\nlarge- scale applications can be used and when working with external\ncollaborators, we have developed a collection of mini-applications that\ncapture the essence of our much larger scientific codes, are readily\napplicable to both large and small systems, and whose run-time\ninformation can accurately reveal problems associated with execution\nefficiency.\n\nGenerating the data is only half the problem, though. We need the\nability to capture platform-relevant mini-app performance data at the\nconvenience of the testers when and where they generate the data. We\nalso need the ability to search through, filter, and visualize the\nresulting performance measurement datasets in detail to identify and\nunderstand trends and patterns.\n\nSandia National Laboratories has developed a performance analysis suite\nprimarily consisting of two tools written in Python, Pylot and Co-Pylot.\nCo- Pylot is a relatively simple interface that enables easy batch\ntransfer of performance data to a remote MySQL database server for\npersistent storage.\n\nOnce stored, the performance data is extracted, organized, filtered, and\nanalyzed using Pylot, a more functionally complex interface. Pylot is\nused to present user-selected MySQL database fields in a variety of\nviews including statistical data, bar and pie charts, Cartesian or\nlog-log or semi-log plots, reference curves for comparisons, and Kiviat\ndiagrams (also called radar charts) for multivariate datasets.\n\nA built-in storage buffer provides the ability to store, compare, and\nanalyze data from multiple databases. This capability is critical for\nstudying performance variations of a code running on a particular\narchitecture, comparing application performance across architectures, or\ncomparing multiple applications on one or more architectures. Values in\nup to four database fields at a time can be mathematically combined to\ngenerate a new temporary field to provide complete generality while\naccessing a database. Further, Pylot provides the ability to easily move\nMySQL databases and tables between computers, including the analyst\u2019s\nlaptop. This coherency of databases across multiple analysis platforms\ncan be used, for example, to avoid network latency issues associated\nwith accessing remote servers. It also serves as a distributed backup\nsystem.\n\nAn outline of this presentation follows:\n\n1. Applications at Sandia National Laboratories (6 mins)\n\n   -  Simulation size and runtime of typical large Sandia applications\n   -  Difficulties of using large-scale applications in early computer\n      system design and analysis\n   -  Mantevo mini-apps \u2013 small, self-contained programs that embody\n      essential performance characteristics of key applications.\n\n2. Gathering data (4 mins)\n\n   -  What information Mantevo mini-apps provide\n   -  Co-Pylot \u2013 getting your data into a remote database\n\n3. Supercomputer and Cluster application analysis (10 mins)\n\n   -  Pylot \u2013 demo of accessing and graphing MySQL data as a method for\n      analyzing performance\n   -  Diagnosing performance issues\n   -  Comparing different systems and different runs\n\n4. Future Extensions of Pylot (5 mins)\n\n   -  Capturing compile-time and execution info\n   -  Efforts to move parts of Pylot to the web\n\n\n",
  "duration": null,
  "id": 450,
  "language": "eng",
  "quality_notes": "",
  "recorded": "2011-03-11",
  "slug": "pycon-2011--supercomputer-and-cluster-application",
  "speakers": [
    "Daniel W. Barnette"
  ],
  "summary": "",
  "tags": [
    "pycon",
    "pycon2011",
    "pylot",
    "sandianationallaboratories",
    "supercomputer"
  ],
  "thumbnail_url": "https://archive.org/services/img/pyvideo_450___supercomputer-and-cluster-application-performance-analysis-using-python",
  "title": "Supercomputer and Cluster Application Performance Analysis using Python",
  "videos": [
    {
      "type": "archive.org",
      "url": "https://archive.org/details/pyvideo_450___supercomputer-and-cluster-application-performance-analysis-using-python"
    }
  ]
}
