{
  "alias": "video/2174/data-processing-with-python-scipy2013-tutorial-7",
  "category": "SciPy 2013",
  "copyright_text": "https://www.youtube.com/t/terms",
  "description": "",
  "duration": null,
  "id": 2174,
  "language": "eng",
  "quality_notes": "",
  "recorded": "2013-06-27",
  "related_urls": [
    "https://github.com/ContinuumIO/tutorials"
  ],
  "slug": "data-processing-with-python-scipy2013-tutorial-7",
  "speakers": [],
  "summary": "Presenters: Ben Zaitlen, Clayton Davis\n\nDescription\n\nThis tutorial is a crash course in data processing and analysis with\nPython. We will explore a wide variety of domains and data types (text,\ntime-series, log files, etc.) and demonstrate how Python and a number of\naccompanying modules can be used for effective scientific expression.\nStarting with NumPy and Pandas, we will begin with loading, managing,\ncleaning and exploring real-world data right off the instrument. Next,\nwe will return to NumPy and continue on with SciKit-Learn, focusing on a\ncommon dimensionality-reduction technique: PCA.\n\nIn the second half of the course, we will introduce Python for Big Data\nAnalysis and introduce two common distributed solutions: IPython\nParallel and MapReduce. We will develop several routines commonly used\nfor simultaneous calculations and analysis. Using Disco -- a Python\nMapReduce framework -- we will introduce the concept of MapReduce and\nbuild up several scripts which can process a variety of public data\nsets. Additionally, users will also learn how to launch and manage their\nown clusters leveraging AWS and StarCluster.\n\nOutline\n\n* Setup/Install Check (15) \n\n* NumPy/Pandas (30) \n\n* Series \n\n* Dataframe\n\n* Missing Data \n\n* Resampling \n\n* Plotting \n\n* PCA (15) \n\n* NumPy \n\n* Sci-Kit Learn \n\n* Parallel-Coordinates \n\n* MapReduce (30) \n\n* Intro \n\n* Disco \n\n* Hadoop\n\n* Count Words \n\n* EC2 and Starcluster (15) \n\n* IPython Parallel (30) \n\n* Bitly Links Example (30) \n\n* Wiki Log Analysis (30)\n\n45 minutes extra for questions, pitfalls, and break\n\nEach student will have access to a 3 node EC2 cluster where they will\nmodify and execute examples. Each cluster will have Anaconda, IPython\nNotebook, Disco, and Hadoop preconfigured\n\nRequired Packages\n\nAll examples in this tutorial will use real data. Attendees are expected\nto have some familiarity with statistical methods and familiarity with\ncommon NumPy routines. Users should come with the latest version of\nAnaconda pre-installed on their laptop and a working SSH client.\n\nDocumentation\n\nPreliminary work can be found at:\nhttps://github.com/ContinuumIO/tutorials\n",
  "tags": [
    "Tech"
  ],
  "thumbnail_url": "https://i1.ytimg.com/vi/5il9zH9-Odg/hqdefault.jpg",
  "title": "Data Processing with Python, SciPy2013 Tutorial, Part 1 of 3",
  "videos": [
    {
      "length": 0,
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=5il9zH9-Odg"
    }
  ]
}
