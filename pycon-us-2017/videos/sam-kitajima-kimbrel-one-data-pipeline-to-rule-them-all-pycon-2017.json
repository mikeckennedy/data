{
  "description": "There are myriad data storage systems available for every use case\nimaginable, but letting application teams choose storage engines\nindependently can lead to duplicated efforts and wheel reinvention. This\ntalk will explore how to build a reusable data pipeline based on Kafka\nto support multiple applications, datasets, and use cases including\narchival, warehousing and analytics, stream and batch processing, and\nlow-latency \"hot\" storage.\n",
  "duration": 1791,
  "recorded": "2017-05-21",
  "speakers": [
    "Sam Kitajima-Kimbrel"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/N6riK1Xtyng/hqdefault.jpg",
  "title": "One Data Pipeline to Rule Them All",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=N6riK1Xtyng"
    }
  ]
}
