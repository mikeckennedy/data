{
  "copyright_text": "Creative Commons Attribution license (reuse allowed)",
  "description": "In this completely demo-based talk, Chris will demonstrate various techniques to post-process and optimize trained Tensorflow AI models to reduce deployment size and increase prediction performance.\n\nFirst, we'll use various techniques such as 8-bit quantization, weight-rounding, and batch-normalization folding, we will simplify the path of forward propagation and prediction.\n\nNext, we'll loadtest and compare our optimized and unoptimized models - in addition to enabling and disabling request batching.\n\nLast, we'll dive deep into Google's Tensorflow Graph Transform Tool to build custom model optimization functions.",
  "duration": 2498,
  "language": "eng",
  "recorded": "2017-07-06",
  "related_urls": [
    {
      "label": "schedule",
      "url": "https://pydata.org/seattle2017/schedule"
    }
  ],
  "speakers": [
    "Chris Fregly"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/_lJJC7BiwVU/maxresdefault.jpg",
  "title": "High Performance Distributed Tensorflow",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=_lJJC7BiwVU"
    }
  ]
}
