{
  "alias": "video/1225/nd-image-segmentation-using-learned-region-agglom",
  "category": "SciPy 2012",
  "copyright_text": "CC BY-SA",
  "description": "One of the principal goals of the Janelia Farm Research Campus is the\nreconstruction of complete neuronal circuits. This involves 3D electron-\nmicroscopy (EM) volumes many microns across with better than 10nm\nresolution, resulting in gigavoxel scale images. From these, individual\nneurons must be segmented out. Although image segmentation is a\nwell-studied problem, these data present unique challenges in addition\nto scale: neurons have an elongated, irregular branching structure, with\nprocesses up to 50nm thin but hundreds of micrometers long); one neuron\nlooks much like the next, with only a thin cellular boundary separating\ndensely packed neurons; and internal neuronal structures can look\nsimilar to the cellular boundary. The first problem in particular means\nthat small errors in segment boundary predictions can lead to large\nerrors in neuron shape and neuronal network connectivity.\n\nOur segmentation workflow has three main steps: a voxelwise edge\nclassification, a fine-grained segmentation into supervoxels (which can\nreasonably be assumed to be atomic groups of voxels), and hierarchical\nregion agglomeration.\n\nFor the first step, we use Ilastik, a pixel-level interactive learning\nprogram. Ilastik uses the output of various image filters as features to\nclassify voxels as labeled by the user. We then use the watershed\nalgorithm on the resulting edge probability map to obtain supervoxels.\nFor the last step, we developed a new machine learning algorithm\n(Nunez-Iglesias et al, in preparation).\n\nPrior work has used the mean voxel-level edge-probability along the\nboundaries between regions to agglomerate them. This strategy works\nextremely well because boundaries get longer as agglomeration proceeds,\nresulting in ever- improving estimates of the mean probability. We\nhypothesized that we could improve agglomeration accuracy by using a\nclassifier (which can use many more features than the mean). However, a\nclassifier can perform poorly because throughout agglomeration we may\nvisit a part of the feature space that has not yet been sampled. In our\napproach, we use active learning to ensure that we have examples from\nall parts of the space we are likely to encounter.\n\nWe implemented our algorithm in arbitrary dimensions in an open-source,\nMIT- licensed Python library, Ray (https://github.com/jni/ray). Ray\ncombines leading scientific computing Python libraries, including NumPy,\nSciPy, NetworkX, and scikits-learn to deliver state of the art\nsegmentation accuracy in Python.\n",
  "duration": null,
  "id": 1225,
  "language": "eng",
  "quality_notes": "",
  "recorded": "2012-07-19",
  "related_urls": [
    "https://github.com/jni/ray)."
  ],
  "slug": "nd-image-segmentation-using-learned-region-agglom",
  "speakers": [
    "Juan Nunez-Iglesias"
  ],
  "summary": "",
  "tags": [
    "General"
  ],
  "thumbnail_url": "https://i2.ytimg.com/vi/-cQpExBrh74/hqdefault.jpg",
  "title": "nD image segmentation using learned region agglomeration with the Ray Python library",
  "videos": [
    {
      "type": "mp4",
      "url": "http://s3.us.archive.org/nextdayvideo/enthought/scipy_2012/nD_image_segmentation_using_le.mp4?Signature=c9cvY2RhvdhwqRDhvE48%2BgY%2Ftp4%3D&Expires=1346444687&AWSAccessKeyId=FEWGReWX3QbNk0h3"
    },
    {
      "length": 0,
      "type": "youtube",
      "url": "http://youtube.com/watch?v=-cQpExBrh74"
    }
  ]
}
