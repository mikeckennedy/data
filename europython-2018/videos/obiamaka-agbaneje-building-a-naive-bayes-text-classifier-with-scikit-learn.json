{
  "copyright_text": "Creative Commons Attribution license (reuse allowed)",
  "description": "Machine learning algorithms used in the classification of text are\nSupport Vector Machines, k Nearest Neighbors but the most popular\nalgorithm to implement is Naive Bayes because of its simplicity based on\nBayes Theorem.\n\nThe Naive Bayes classifier is able to memorise the relationships between\nthe training attributes and the outcome and predicts by multiplying the\nconditional probabilities of the attributes with the assumption that\nthey are independent of the outcome. It is popularly used in classifying\ndata sets that have a large number of features that are sparse or nearly\nindependent such as text documents.\n\nIn this talk, I will describe how to build a model using the Naive Bayes\nalgorithm with the scikit-learn library using the spam/ham youtube\ncomment dataset from the UCI repository. Preprocessing techniques such\nas Text normalisation and Feature extraction will be also be discussed.\n",
  "duration": 1784,
  "language": "eng",
  "recorded": "2018-07-26",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://ep2018.europython.eu/p3/schedule/ep2018/"
    }
  ],
  "speakers": [
    "Obiamaka Agbaneje"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/yUuxJygQvpI/maxresdefault.jpg",
  "title": "Building a Naive Bayes Text Classifier with scikit-learn",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=yUuxJygQvpI"
    }
  ]
}
