{
  "description": "| Parallel computing in Python: Current state and recent advances\n| ---------------------------------------------------------------\n\n| Modern hardware is multi-core. It is crucial for Python to provide\n| high-performance parallelism. This talk will expose to both\n  data-scientists and\n| library developers the current state of affairs and the recent\n  advances for\n| parallel computing with Python. The goal is to help practitioners and\n| developers to make better decisions on this matter.\n\n| I will first cover how Python can interface with parallelism, from\n  leveraging\n| external parallelism of C-extensions \u2013especially the BLAS family\u2013 to\n  Python's\n| multiprocessing and multithreading API. I will touch upon use cases,\n  e.g single\n| vs multi machine, as well as and pros and cons of the various\n  solutions for\n| each use case. Most of these considerations will be backed by\n  benchmarks from\n| the scikit-learn machine\n| learning library.\n\n| From these low-level interfaces emerged higher-level parallel\n  processing\n| libraries, such as concurrent.futures, joblib and loky (used by dask\n  and\n| scikit-learn) These libraries make it easy for Python programmers to\n  use safe\n| and reliable parallelism in their code. They can even work in more\n  exotic\n| situations, such as interactive sessions, in which Python\u2019s native\n| multiprocessing support tends to fail. I will describe their purpose\n  as well as\n| the canonical use-cases they address.\n\n| The last part of this talk will focus on the most recent advances in\n  the Python\n| standard library, addressing one of the principal performance\n  bottlenecks of\n| multi-core/multi-machine processing, which is data communication. We\n  will\n| present a new API for shared-memory management between different\n  Python\n| processes, and performance improvements for the serialization of large\n  Python\n| objects ( PEP 574, pickle extensions). These performance improvements\n  will be\n| leveraged by distributed data science frameworks such as dask, ray and\n  pyspark.",
  "language": "eng",
  "recorded": "2019-07-12",
  "speakers": [
    "Pierre Glaser"
  ],
  "tags": [
    "Distributed Systems",
    "Multi-Processing",
    "Multi-Threading",
    "Performance",
    "Scientific Libraries (Numpy/Pandas/SciKit/...)"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/UVL4LFy8ch0/hqdefault.jpg",
  "title": "Parallel computing in Python: Current state and recent advances",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=UVL4LFy8ch0"
    }
  ]
}
