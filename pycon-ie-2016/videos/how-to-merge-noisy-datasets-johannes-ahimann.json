{
  "description": "Acquiring large datasets is quite simple these days on the internet,\nbut data is often noisy and most of the value often lies in combining,\nconnecting and merging multiple datasets from different sources.\n\nThis talk gives an overview of Probabilistic Record Matching, i.e. the\nchallenges posed when dealing with noisy data, how to normalize data\nand how to match noisy records to each other.\n\nThe goal of the presentation is to give participants an understanding\nof the possibilities and challenges of merging datasets, as well as\nmention some of the amazing python libraries available.\n\nTopics discussed: normalization of attributes, approximate string\nmatching, performance, similarity clustering\n",
  "duration": 1597,
  "language": "eng",
  "recorded": "2016-11-06",
  "speakers": [
    "Johannes Ahlmann"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/1BjiTC5O_rc/hqdefault.jpg",
  "title": "How to Merge Noisy Datasets",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=1BjiTC5O_rc"
    }
  ]
}
