{
  "copyright_text": null,
  "description": "A serving system for Deep Learning models is a tricky design problem. It's a large scale production system, so we want it to scale well, adapt to changing traffic patterns, and have low latency. It\u2019s also part of the Data Scientist\u2019s core loop - so it should be very flexible, and running an experiment on live traffic should be easy. In this talk, I\u2019ll discuss key design considerations for such a system covering both perspectives. I\u2019ll also describe a system we built at Taboola for serving TensorFlow models. It serves billions of requests per day, spread over dozens of models, and still has pretty good ergonomics,",
  "duration": 3355,
  "language": "eng",
  "recorded": "2018-06-05",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://il.pycon.org/2018/schedule/"
    },
    {
      "label": "Talk slides",
      "url": "https://s3-eu-west-1.amazonaws.com/pyconil-data-amit/presentations/Deep+Model+Serving+-+PyCon+'18.pdf"
    }
  ],
  "speakers": [
    "Jenia Gorokhovsky"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/82YaH2YvWSs/maxresdefault.jpg",
  "title": "Deep model serving - scale and ergonomics",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=82YaH2YvWSs"
    }
  ]
}
