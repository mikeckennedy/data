{
  "copyright_text": "Creative Commons Attribution license (reuse allowed)",
  "description": "As data-driven models are more commonly used in decision-making and public policy, we as data practitioners must be aware of the systematic biases present in our data, so we do not discriminate or reinforce vicious cycles against vulnerable groups.  I will explain the concept of algorithmic fairness and how it relates to the traditional view of machine learning classifiers. I will discuss ways to measure the extent to which a classifier discriminates against a particular minority group and showcase special algorithms for mitigating the level of disparate impact of a classifier. At the end of the talk, I will point interested audience members to resources where they can learn more about emerging trends in this topic.",
  "duration": 1500,
  "language": "eng",
  "recorded": "2017-10-06",
  "related_urls": [
    "https://2017.pygotham.org/talks/algorithmic-fairness-and-algorithmic-discrimination/"
  ],
  "speakers": [
    "Manojit Nandi"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/iaV5EiBkv7Q/maxresdefault.jpg",
  "title": "Algorithmic fairness and algorithmic discrimination",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=iaV5EiBkv7Q"
    }
  ]
}
