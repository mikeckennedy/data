{
  "description": "\"Deploying ML Solutions With Low Latency In Python\" by: Aditya Lohia\nWhen we aim for better accuracies, sometimes we forget that the algorithms become more massive and slower. This fact renders the algorithms unusable in real-time scenarios. How do you deploy your solution? Which framework to use? Can you use Python for deploying my solution? Can you use Jetson Nano for multi-stream inferencing? If you are curious to solve these questions, join me in this talk to discover TensorRT and DeepStream and how they reduce your algorithm\u2019s latency and memory footprint. NVIDIA TensorRT\u2122 is an SDK for high-performance deep learning inference. It includes a deep learning inference optimizer and runtime that delivers low latency and high-throughput for deep learning inference applications. DeepStream offers a multi-platform scalable framework with TLS security to deploy on edge and connect to any cloud. If you are using a GPU and CUDA/Tensor cores, you can leverage the SDK framework to deploy bigger and better algorithms for your real-time scenarios. The main focus of this talk will be to demonstrate why, where, and how to use TensorRT and DeepStream.\n\nRecorded at the 2021 Python Web Conference (https://2021.pythonwebconf.com)",
  "duration": 2085,
  "language": "eng",
  "recorded": "2021-03-22",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://2021.pythonwebconf.com/schedule"
    },
    {
      "label": "Talk announcement",
      "url": "https://2021.pythonwebconf.com/presentations/deploying-ml-solutions-with-low-latency-in-python"
    }
  ],
  "speakers": [
    "Aditya Lohia"
  ],
  "tags": [
    "PythonWebConf",
    "PythonWebConf2021"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/mMQ6mGQtwX8/hqdefault.jpg",
  "title": "Deploying ML Solutions With Low Latency In Python",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=mMQ6mGQtwX8"
    }
  ]
}
