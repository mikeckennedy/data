{
  "copyright_text": "Creative Commons Attribution license (reuse allowed)",
  "description": "Goal of the Tutorial\n\n-  **Introduce** main features of Keras APIs to build Neural Networks.\n-  **Learn** how to implement simple and complex Deep Neural Networks\n   Architectures using Keras.\n-  **Discover** Keras Implementation and Internals.\n\n-  **Note**: examples and hands-on exercises will be provided along the\n   way.\n\n#. *Multi-layer Fully Connected Networks (and the ``backends``)*\n#. *Bottleneck features and Embeddings*\n#. *Convolutional Networks*\n#. *Transfer Learning and Fine Tuning*\n#. *Residual Networks*\n#. *Recursive Neural Networks*\n#. *[Variational] AutoEncoders and Adversarials*\n#. *Multi-Modal Networks*\n#. *Custom Layers and Optimisers*\n#. *Interactive Networks and Callbacks*\n\n--------------\n\nDescription\n===========\n\n#. | *Multi-layer Fully Connected Networks*\n   | In this notebook we will learn the basic building blocks of Keras\n     APIs to create deep neural networks. We will learn how to use the\n     ``Sequential`` object as well as *Functional* and ``keras.backend``\n     APIs. First examples of MLP and Fully Connected Networks will be\n     presented.\n\n#. | *Bootleneck Features and Embeddings*\n   | After having played a bit with Keras APIs for building networks, we\n     start learn how to inspect network's internals. In details, we will\n     learn (1) how to iterate over layers; (2) how to initialise and get\n     weights; (3) how to extract bottleneck features and create\n     embeddings.\n\n#. | *Convolutional Networks*\n   | This notebook will teach how to build CNN (Convolutional Neural\n     Networks). Convolutional, Pooling, DropOut layers will be\n     presented, along with clear description on how to properly apply\n     convolutions on images, depending on ``image_dim_ordering``\n     setting.\n\n#. | *Transfer Learning and Fine Tuning*\n   | The Keras implementation of some famous Deep Convolutional Networks\n     will be presented (i.e. ``keras.applications.vgg16``,\n     ``keras.applications.vgg19``, and\n     ``keras.applications.inceptionv3``). We will learn how to leverage\n     on these models for transfer learning and fine tuning using Keras\n     ``Layer`` APIs.\n\n#. | *Residual Networks*\n   | In this notebook, Residual Networks will be presented. In\n     particular, the Keras implementation of the residual network\n     topology will be explained. Then, ResNet\n     (``keras.applications.resnet50``) Keras implementation will be\n     detailed.\n\n#. | *Recurrent Neural Networks*\n   | Recurrent Neural Networks (i.e. LSTM and GRU) are the main topic of\n     this notebook. The Keras implementation of these two types of\n     network will be presented along with working examples combining\n     Word Embeddings and Convolutional Layers (i.e.\n     ``keras.layers.convolutional_recurrent``)\n\n#. | *[Variational] AutoEncoders and Adversarials*\n   | This notebook will be devoted to show how to implement AutoEncoders\n     in Keras. In particular, the implementation of Stacked\n     AutoEncoders, Variational AutoEncoders and Generative Adversarial\n     Networks will be presented.\n\n#. | *Multi-Modal Networks*\n   | Multi-Input and Multi-task Networks are the fundamental steps for\n     advanced deep networks. This notebook will provide implementation\n     recipes and examples.\n\n#. | *Custom Layers and Optimisers*\n   | This notebook will provide details and examples of Keras internals.\n     In particular, we will learn how to implement a Custom Layer in\n     Keras, and custom Activation functions, and custom optimisers.\n\n#. | *Interactive Networks and Callbacks*\n   | In this last notebook, ``keras.callbacks`` will be explained.\n     Callbacks to track and monitor network performances during the\n     training process will be built and integrated inside a web app.\n     Finally, an example of ``keras-js`` will be described, detailing\n     functions in Keras to export models and weights (in ``json`` and\n     ``hdf5`` formats).\n\nRequirements\n============\n\nThis tutorial requires the following packages:\n\n-  | Python version 3.5.x\n   | - Python 3.4 is fine as well\n   | - likely Python 2.7 would also be fine, but *who knows*? :P\n\n-  ``numpy`` version 1.10 or later: http://www.numpy.org/\n-  ``scipy`` version 0.16 or later: http://www.scipy.org/\n-  ``matplotlib`` version 1.4 or later: http://matplotlib.org/\n-  ``pandas`` version 0.16 or later: http://pandas.pydata.org\n-  ``scikit-learn`` version 0.15 or later: http://scikit-learn.org\n-  ``keras`` version 1.0 or later: http://keras.io\n-  ``tensorflow`` version 0.9 or later: https://www.tensorflow.org\n-  ``ipython``/``jupyter`` version 4.0 or later, with notebook support\n\n(Optional but recommended):\n\n-  ``pyyaml``\n-  ``hdf5`` and ``h5py`` (required if you use model saving/loading\n   functions in keras)\n\nThe easiest way to get (most) these is to use an all-in-one installer\nsuch as `Anaconda <http://www.continuum.io/downloads>`__ from Continuum.\nThese are available for multiple architectures.",
  "duration": 5434,
  "language": "eng",
  "recorded": "2017-08-31",
  "related_urls": [
    {
      "label": "schedule",
      "url": "https://www.euroscipy.org/2017/program.html"
    }
  ],
  "speakers": [
    "Valerio Maggio"
  ],
  "tags": [
    "tutorial"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/DO3tn_I1P-8/maxresdefault.jpg",
  "title": "Keras",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=DO3tn_I1P-8"
    }
  ]
}
