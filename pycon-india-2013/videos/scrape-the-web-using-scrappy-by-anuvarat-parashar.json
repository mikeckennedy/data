{
  "abstract": "Learn to use\n`scrapy <https://web.archive.org/web/20140314031722/http://scrapy.org/%20%22Scrapy%22>`__\nfor crawling the web.",
  "copyright_text": null,
  "description": "| Extracting structured information from a webpages is a relatively\n  simple task in python, given the innumerable tools at our disposal\n  namely BeautifulSoup, PyQuery, lxml etc. However, crawling and\n  scraping data from multiple websites makes the job difficult because\n  everyone on the internet likes to structure their information\n  differently.\n| Crawling upto 10 portals is manageable upto 10 portals, beyond that it\n  becomes a menace. What we need then, is a framework to keep the\n  crawling and parsing logic separate and also help manage the parsers.\n  This is where scrapy comes to our assistance. It is the most pythonic\n  way of scraping the web.",
  "duration": 2968,
  "language": "eng",
  "recorded": "2013-09-01",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://in.pycon.org/2013/index.html#schedule"
    }
  ],
  "speakers": [
    "Anuvrat Parashar"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/JqabCQkJF3g/maxresdefault.jpg",
  "title": "Scrape the web using Scrapy",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=JqabCQkJF3g"
    }
  ]
}
