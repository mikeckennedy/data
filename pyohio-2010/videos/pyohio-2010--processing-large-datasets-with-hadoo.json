{
  "alias": "video/504/pyohio-2010--processing-large-datasets-with-hadoo",
  "category": "PyOhio 2010",
  "copyright_text": "Creative Commons Attribution-NonCommercial-ShareAlike 3.0",
  "description": "Processing Large Datasets with Hadoop and Python\n\nPresented by William McVey\n\nThis talk will explore how Hadoop along with Python can be used to\nprocess large datasets. An overview of the Apache Hadoop project will be\ngiven. The map/reduce concept will be introduced and some methods of\ncoding the data processing routines in python will be explored. The talk\nwill use real world examples to illustrate how this approach can be used\nto parallelize computationally expensive operations across multiple\ncluster nodes effectively using python.\n\nThe course will assume familiarity with the Python language during the\ndemos, but will not actually require a deep knowledge of python to\nunderstand the concepts introduced.\n",
  "duration": null,
  "id": 504,
  "language": "eng",
  "quality_notes": "",
  "recorded": "2010-07-31",
  "slug": "pyohio-2010--processing-large-datasets-with-hadoo",
  "speakers": [
    "William McVey"
  ],
  "summary": "",
  "tags": [
    "datasets",
    "hadoop",
    "pyohio",
    "pyohio2010"
  ],
  "thumbnail_url": "https://archive.org/services/img/pyvideo_504___pyohio-2010-processing-large-datasets-with-hadoop-and-python",
  "title": "PyOhio 2010: Processing Large Datasets with Hadoop and Python",
  "videos": [
    {
      "type": "archive.org",
      "url": "https://archive.org/details/pyvideo_504___pyohio-2010-processing-large-datasets-with-hadoop-and-python"
    }
  ]
}
