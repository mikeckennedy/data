{
  "description": "**Introduction**\n\nStarcount has been developing automated methods to understand the\ncommunity structure of online society and the influencers within these\ncommunities. This helps marketers go beyond individually targeted\nadverts, identifying better ways for them to engage with relevant\ncommunities and allowing them to make positive contributions and offer\nservices and products of real value. With billions of people using\nsocial media across the world, pinpointing the right communities to\ntarget is a challenging problem. We use Python to develop software that\nis able to search for influencers, the communities who connect with\nthem, and the passions they share. Ultimately we hope to make social\nmedia spam a thing of the past, replacing it with useful information,\nand positive contributions to engaged communities.\n\nIn this talk we will describe an end-to-end Python stack that goes from\ndata acquisition through API calls to social networks all the way to\ncommunity detection and labelling and show how several major Python\nlibraries are meshed together to achieve these ends.\n\nWe break the pipeline down into 4 major components: data acquisition\nwith Twisted, data formatting and network construction with Pandas, Data\ncompression with Numpy and Cython and Data Enrichment with Scikit-learn.\n\n**Data Extraction**\n\nWe have developed a client/server program that enables us to download\nuser profile, connections and user post data from various social\nnetworks, including: Twitter, Facebook and Instagram. The server is\nstarted with a list of network IDs to perform an operation against and\naccess tokens to validate the operations. Once started it manages access\nrate limits and the distribution of work across a network of client\napplications. The clients perform the actual requests to the external\nAPIs using asynchronous HTTPS requests. The Twisted event-driven network\nengine is used to provide features such as an event loop and\nasynchronous network calls as well as a simple custom client server\ncapability.\n\nOur core hypothesis is that social networks can be understood, at least\nfor commercial purposes, in terms of the interactions surrounding the\nmajor influencers. Due to API limits, restricting the amount of data\nthat can be gathered, managing the size of your network is an important\nconsideration. The final product of our data extraction process is a\ndirectory populated with the following file data:\n\n-  Follower Metadata\n-  Influencer Metadata\n-  Follower-influencer Relationships\n\n**Network Construction**\n\nWe believe that the best way to summarise the interests of social media\nusers is to understand what they follow and so we store links between\ninfluencers and their followers. Our graph model differs from the\nstandard network graph as it has two distinct types of nodes,\ninfluencers and followers, which are treated differently. The\nrelationships between followers and influencers are key to understanding\na network's user base.\n\nSeveral of our processes require a full linear scan of the\nfollower-influencer connection database. This can be a time-consuming\ntask. We store each of the follower-influencer files in a numpy binary\nformat to enable very fast reads over the data. We have used Cython to\nspeed up this core processing significantly from our starting point of a\npure Python implementation. We store each of these files in 1% percent\nsamples, each of which contains roughly 7 million rows and parallelise\nexecution using the multiprocessing and joblib libraries.\n\n**Compression**\n\nWe wish to detect communities of influencers and so we need a way of\ndetermining relationship strengths between them. Our method is based on\nthe number of shared followers. The networks are too large and dynamic\nfor it to be practical to store all pairs of similarities and so instead\nwe compress each influencer in a form that allows similarities to be\nquickly calculated when needed. This compression takes the form of\nminhash signatures. While using the signatures is very quick, generating\nthem is an expensive operation that must iterate through billions of\nfollower-influencer connections, incrementally updating the signatures.\nOur original implementation of this algorithm took six days to run.\n\nWe were able to make some improvements by profiling the code using\ncProfiler and line\\_profiler to remove bottlenecks. Really significant\nimprovements were achieved by pre-processing our input data into a more\nsuitable format (binary numpy memmap) and using a Cython main loop. In\nthis specific case we managed to improve on the speed of numpy matrix\noperations (with broadcasting) by writing c-code which created less\nintermediate variables and hence made less calls to create new objects\non the heap. The cython annotation tool proved useful in identifying\nwhen cPython was actually creating Python objects, especially when these\nwere non-obvious like views on a numpy array. In total these\noptimisations reduce runtime from six days to three hours.\n\n**Enrichment**\n\nThe final stage of our process uses machine learning algorithms to infer\nuser attributes. These may include demographics data such as country,\nage and gender; or more advanced features such as robot detection - is\nthe user a person, Twitter bot or company.\n\nWe used the scikit-learn package which contains tools to develop machine\nlearning projects quickly. We typically progress by splitting the data\ninto different sets for cross-validation before training a\nclassification model such as a support vector machine or random forest.\nThe initial model would be tuned using scikit-learn\u2019s grid search and\nfinally evaluated using validation and learning curves. Like many other\nfeatures, scikit-learn\u2019s support vector machine is implemented using\nfast and highly optimised C libraries.\n\n**Conclusion**\n\nIn this talk we have described how a stack compose entirely from Python\ncomponents can take raw data directly from social network APIs and\nmanipulate it into a form that allows brand managers to interactively\nunderstand the communities and influencers that exist around their\nproducts and marketplaces.\n",
  "duration": 1584,
  "language": "eng",
  "recorded": "2015-06-21",
  "speakers": [
    "Benjamin Chamberlain",
    "Davide Donato",
    "Josh Levy-Kramer"
  ],
  "summary": "A Python stack for social network analytics. The pipeline connects\ndata acquisition through API calls to community detection and\nlabelling. Several major Python libraries are discussed. There are 4\nsections: data acquisition with Twisted, data formatting and network\nconstruction with Pandas, Data compression with Numpy and Cython and\nData Enrichment with Scikit-learn.",
  "thumbnail_url": "https://i.ytimg.com/vi/R7i8Vcm9GZM/hqdefault.jpg",
  "title": "A practical guide to conquering social network data",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=R7i8Vcm9GZM"
    }
  ]
}
