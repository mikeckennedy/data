{
  "alias": "video/3044/amanda-a-new-generation-of-distributed-services",
  "category": "EuroPython 2014",
  "copyright_text": "http://creativecommons.org/licenses/by/3.0/",
  "description": "Presentation outline\n====================\n\nWe'll start off with a quick overview of a movie production pipeline\nwhich will set the stage for how Amanda provides artists with the tools\nthey need to develop and streamline the production process as well as\nAmanda's crucial function as a robust framework for the support and\ndevelopment teams. Going over some stats, up to 250.000 service calls a\nminute during World War Z for example (for frame of reference this is\ntwice the average rate of stackoverflow.com), I'll highlight some of the\nproblems encountered with the 1st generation. Initially developed in\n2007 and replaced last year it had several flaws in regards to\nscalability, maintainability and future proofing. From there I'll\nintroduce the 2nd generation which is build on the principle of\ncomponentisation and building blocks. Every part of the system needs to\nbe replaceable and this needs to be possible from the configuration.\n\nDuring the presentation we will be stepping through the different\nbuilding blocks, how they have been set up, how they slot together and\nhow we monitor, trace and test the system from the ground up. Starting\nat the lowest level with services we'll slowly step through the\ndifferent blocks necessary to build a fault tolerant, distributed and\nscalable platform. We made sure that the platform is not tied into any\nspecific technology but allows the use of the best technologies\ndepending on the type of work being undertaken and changing business\nneeds and technological advances.\n\nService development and testing\n-------------------------------\n\nOur development teams build applications for artists creating visual\neffects through to management teams coordinating productions. A\nservice-based architecture was chosen to provide consistent interfaces\nacross the many different environments where this is required. We\nprovide an ecosystem where developers of any level can safely write a\nservice (a set of instructions regarding a specific topic) that are\npresented to developers and technical artists globally. To write a\nservice the developer doesn't need any knowledge in regards to building\nlarge concurrent systems. The service is implemented through a simple\nPython API and the provided ecosystem allows services to exist in a\nstandalone manner. The service concept was separated from the platform\nhosting it. This allows hosting in any application that provides a\nstandard container (a service provider). Extracting this allowed for\nmore rigorous and simple testing of services; it also allows developers\nto provide fake versions of their services publicly against which client\ncode can be tested. The adage \u00ca\u00bbeverything as a service\u00ca\u00bc was applied to\nthe development of internal facilities. This includes our management\ntools and the developer console, which presents the documentation of\nservices and methods available to developers through a web interface.\nInfrastructure services were introduced to present an interface to\nfacilities provided to a regular service, for example databases,\nconfiguration and centralized logging. Services can call other services\nand, similarly to infrastructures, services can be replaced with\ndifferent services depending on the configuration. Services are exposed\nto a service (or client as we will see later) via a service provider\njust like in applications. Setting services up with the above patterns\nallows developers to iterate quickly and to include services within\ntesting frameworks. It has also provided a standardized form across\nprojects allowing developers to support and add to unfamiliar code\neasily. And last but not least it has given us full abstractions at all\nlevels, users of services do not need to know the code underneath the\nhood be it at a service level or at an infrastructure level.\n\nBuilding the cluster\n--------------------\n\nRather than building a single system, the new architecture defines a set\nof building blocks for constructing a distributed service platform.\nThese can provide adapters for best of breed third party tools or, where\nnecessary, custom implementations of functionality. Configuration is\nused to determine the number and types of modules to use and the\nparameters with which to initialize them. This allows the same platform\nto be used for small instances at a developer\u00ca\u00bcs desk up to a production\nenvironment of many nodes. The design enables improved components to be\nswapped into the existing system whilst forming the basis for an\nentirely new design.\n\nMost practical applications require the service provider to handle\nmultiple requests at the same time. Amanda provides a set of\ninterchangeable concurrency modules. This allows the most appropriate\nPython model for parallel processing to be chosen. For work involving\nheavy I/O work we choose approaches that avoid waiting for the GIL, for\nexample multiple processes and greenlets/coroutines, whilst for CPU\nbound work we can use threads which may prove more performant. Having\nthe option to choose between mechanisms is important since there is not\na solution that neatly fits all use cases. A pluggable concurrency\nabstraction also allows integration of new libraries as they become\navailable. In future this might include the new asyncio (formerly Tulip)\ncore library for Python 3.3+.\n\nTo benefit from concurrency, resource pooling, caching etc. we don't\nalways want to execute the service locally to the service provider.\nService proxies implement this behavior; they take the service, method\nand arguments of a request as their input and return the result. The\nproxy should be transparent to the service and service provider\ncomponents. By chaining proxies, complex routing schemes can be built or\nanalysis performed on the results returned. Some similarity can be drawn\nwith middle-ware in the Web Services Gateway Interface (WSGI)\nspecification. Communication between proxy and service provider is\nserved by the transport. This abstraction provides an asynchronous\ninterface to underlying technologies \u00e2\u20ac\u201c Current implementations include\nqueue based AMQP, ontop of RabbitMQ, and \u00c3\u02dcMQ and more na\u00c3\u00afve\ncommunications with standard UDP and TCP sockets. Most transports define\nboth client and server parts of the system \u00e2\u20ac\u201c however some,\nparticularly HTTP-based transports, are designed to accept requests\ndirectly from external clients. Requests from external applications\ncommonly use XMLRPC, JSONRPC or straight JSON. Transport implementations\ncan be interchanged without impacting other components of Amanda or\nservice developers.\n\nIn production, a request gateway implemented as a WSGI application\nfronts the HTTP protocols. Using the standard web components NGINX and\n\u00ce\u00bcWSGI we can build a very scalable front end which internally uses the\nservice provider, proxy, transport pattern to offload the requests to a\nbackend. The gateway can also provide standard web facilities such as\ntemplate rendering (through the Jinja2 library1) for general web\nclients. The gateway was a requirement as requests originate from\napplications written in many languages including C++, Python, JavaScript\nand domain specific languages such as mel. For us it was important that\nthe client used across all those languages was a proven standard and\nlightweight. Most requests are served in near realtime (6ms round trip\ntimes) and are presented to the client in a synchronous way so using a\nfrontend that supports a large number of HTTP like protocols allowed us\nto keep the clients simple and present the platform to an extremely wide\nvariety of languages. Additionally, through the frontend, we can render\na web page and present that directly if the requests was made from a\nbrowser.\n\nThe final behavior of the platform is defined in configuration. This\nallows the platform to be tuned to suit the work that a particular\nservice is performing (I/O vs CPU bound). It is important to remember\nthat every single component mentioned above be it the concurrency,\ntransport, proxies or frontend can be changed, removed, updated without\nit impacting the service, the developer or any of the other components\nthat make up the platform.\n\nAlso important to mention that internally and externally everything is a\nqueue and presented as a queue. Going from the client to the frontend\nthere is a queue, from the frontend onto the backend there is a queue\netc. all the way down to a request being read of the transport and\nstored inside a queue until a concurrency object is ready to handle the\nrequest with the service provider.\n\nThis is where we think our platform might take a different approach.\nRather than building the platform on top of a single great technology we\ndidn't want to limit ourselves and be able to use all the other great\ntechnologies out there. There is no perfect solution for all problems\nbut allowing to fine tune the platform according to different problems.\nThe setup can now evolve in line with technological advancements and\nchanges to the industry.\n\nMaintenance and Monitoring (5 mins)\n-----------------------------------\n\nWe will walk through how we are using the same setup with services,\nservice providers, proxies and transports to manage clusters around the\nglobe. Once again for our maintenance and monitoring we made sure\neverything is done as a service so that if there is a better tool in the\nfuture we could adopt it.\n\nThrough leveraging the configuration management and remote execute\nplatform Salt, a new cluster can now be provisioned quickly. Management\nis itself provided as a service. Through this system, the current state\nis available and configuration changed across all servers globally. This\nhas reduced routine maintenance tasks from a half day to a five-minute\ntask, with less chance of human error. Monitoring and introspection are\nprovided, as a service, to aid in day-to-day support, tuning and to help\nsupport analysis for future development.\n\nDevelopers of services can trace requests from when they enter the\nsystem, producing a report of the sequence of methods being called, with\nthe supplied arguments. For each call the time spent to fulfill each\nrequest is presented. Care was taken to minimize the impact of this on\nreturn result of the request. Due to everything being a queue we can\ncollect the metrics after the result has been put back onto the\ntransport and send to the user and thus minimize the impact of this\ncollection on returning the result of the request This means that there\nis no requirement to put the system into a debug mode in order to obtain\nexecution metrics.\n\nWith logging being a service we can dynamically change the logging\nconfiguration on a per service basis by making a request to the logging\nservice taking away the need of changing configuration and restarting\nthe service which often means a problem might have disappeared due to\nthe reset.\n\nFuture/Conclusion (1 min)\n-------------------------\n\nWhilst developing the new generation of the platform there have been a\nnumber of possible applications that have emerged. The way in which we\nare able to scale the system would be suitable to run in a cloud\nenvironment \u00e2\u20ac\u201c especially with the improvements to management allowing\nnew nodes to be provisioned quickly. The ease of writing and integrating\nnew components would allow integration with infrastructure provided by\nthird-party cloud vendors. Other areas of interest include a smaller\nversion of the platform running locally on a user\u00ca\u00bcs workstation and\nservices for management of generic processes.\n\nMain technologies and libraries currently used:\n-----------------------------------------------\n\n-  Threading\n-  Gevent\n-  Eventlet\n-  Multiprocessing\n-  ZeroMQ\n-  RabbitMQ\n-  uwsgi\n-  Flask\n-  Salt\n-  nginx\n\n",
  "duration": null,
  "id": 3044,
  "language": "eng",
  "quality_notes": "",
  "recorded": "2014-07-22",
  "slug": "amanda-a-new-generation-of-distributed-services",
  "speakers": [
    "Jozef van Eenbergen"
  ],
  "summary": "To help create award winning visual effects, MPC developed a distributed\nservice-oriented platform, Amanda. Amanda allows developers of any level\nto write a service that is presented to users across 8 facilities\nglobally without them requiring any knowledge of building large\nconcurrent systems. It allows artists and developers across different\ndomains to work with clearly defined API's and gives the service\ndeveloper control over what and how data can and should be accessed. The\ntalk will cover how to set up such a platform from the ground up.\nStarting at the service level building it out with additional modules\nand technologies until the fully distributed system, covering topics\nsuch as concurrency, componetisation and monitoring that allow the fine\ntuning of setups depending on the type of work being undertaken and\nchanging business needs.\n",
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/bPNGn1XHCKw/hqdefault.jpg",
  "title": "Amanda: A New Generation of Distributed Services Framework",
  "videos": [
    {
      "length": 0,
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=bPNGn1XHCKw"
    }
  ]
}
