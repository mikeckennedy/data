{
  "copyright_text": null,
  "description": "Helping companies to be better citizens of the world means providing them with information about a myriad of issues such as Human Rights, Diversity, Climate Change, Carbon Emissions, etc., and helping them prioritise the different signals. For us Python developers and data scientists, this means working with thousands of sources of different types (PDF, HTML, text, Tweets, etc.) and building a scalable and flexible data pipeline that can ingest, analyse, normalise and summarise all these signals.\n\nWe decided to use Python to hook up all the components of our stack. At the core of our data application lies spaCy, which is the natural language processing engine enabling the extraction of meaningful information from large amounts of textual data.\n\nWe will present our workflow at a conceptual level (collecting data, textual analysis, creating insights). We will then describe the different components of our stack and why we chose them (Mongo, ElasticSearch, spaCy, AWS). Finally, we will share the lessons we have learned along the way on this challenging journey. Examples and code illustrating the main points will also be discussed during the talk.\n",
  "duration": 1373,
  "language": "eng",
  "recorded": "2018-10-07",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://2018.es.pycon.org/#schedule"
    }
  ],
  "speakers": [
    "J\u00e9r\u00f4me Basdevant",
    "Jos\u00e9 Manuel Mart\u00ednez Mart\u00ednez"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/zghmyT1b-6Q/maxresdefault.jpg",
  "title": "From chaos to insights: the challenges of extracting meaningful information from unstructured data with Python and spaCy",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=zghmyT1b-6Q"
    }
  ]
}
